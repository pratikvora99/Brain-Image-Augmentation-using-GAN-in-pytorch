{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"Model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"DLJ8hpTT2zoM","colab_type":"code","colab":{}},"source":["import torch\n","import torchsummary\n","from torch import nn\n","from torch.nn.utils import spectral_norm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GR0i9Bgw2zoS","colab_type":"code","colab":{}},"source":["device=\"cuda\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b3bQvScP2zoW","colab_type":"code","colab":{}},"source":["class CCNR(nn.Module):\n","    \n","    def __init__(self,in_ch,out_ch,use_bias):\n","        super(CCNR, self).__init__()\n","        self.conv1x1 = nn.Conv2d(in_ch, out_ch//2, kernel_size=1, stride=1, padding=0, bias=use_bias)\n","        self.conv3x3 = nn.Conv2d(in_ch, out_ch//2, kernel_size=3, stride=1, padding=1, bias=use_bias)\n","        self.lr = nn.LeakyReLU()\n","    \n","    def forward(self,im):\n","        \n","        o1 = self.conv1x1(im)\n","        o2 = self.conv3x3(im)\n","        o3 = self.lr(torch.cat([o1,o2],dim=1))\n","        return o3\n","    \n","    \n","class CCAM(nn.Module):\n","    \n","    def __init__(self,in_ch):\n","        super(CCAM,self).__init__()\n","        \n","        self.denses = nn.Sequential(\n","                        *[nn.Linear(in_ch+4,in_ch//4),\n","                        nn.LeakyReLU(),\n","                        nn.Linear(in_ch//4,in_ch//4),                         \n","                        nn.LeakyReLU(),\n","                        nn.Linear(in_ch//4,in_ch),\n","                        nn.Sigmoid()]\n","                        )\n","        \n","    def forward(self,im,mask):\n","        o1 = self.denses(torch.cat([torch.mean(im,dim=[2,3],keepdim=False),mask],dim=1))\n","        return torch.mul(im,o1.view(o1.shape[0],o1.shape[1],1,1))\n","    \n","    \n","class Generator(nn.Module):\n","    \n","    def __init__(self,in_ch,use_bias,st_ch=4):\n","        super(Generator, self).__init__()\n","        self.in_ch = in_ch\n","        \n","        \n","        #Encoder A layers\n","        self.enc_a0_0 = CCNR(in_ch,st_ch,use_bias)\n","        self.enc_a0_1 = CCNR(st_ch,st_ch,use_bias)\n","        self.pool_a0 = nn.Conv2d(st_ch, st_ch*2, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_a1_0 = CCNR(st_ch*2,st_ch*2,use_bias)\n","        self.enc_a1_1 = CCNR(st_ch*2,st_ch*2,use_bias)\n","        self.pool_a1 = nn.Conv2d(st_ch*2, st_ch*4, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_a2_0 = CCNR(st_ch*4,st_ch*4,use_bias)\n","        self.enc_a2_1 = CCNR(st_ch*4,st_ch*4,use_bias)\n","        self.pool_a2 = nn.Conv2d(st_ch*4, st_ch*8, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_a3_0 = CCNR(st_ch*8,st_ch*8,use_bias)\n","        self.enc_a3_1 = CCNR(st_ch*8,st_ch*8,use_bias)\n","        self.pool_a3 = nn.Conv2d(st_ch*8, st_ch*16, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        #Encoder B layers\n","        self.enc_b0_0 = CCNR(in_ch,st_ch,use_bias)\n","        self.enc_b0_1 = CCNR(st_ch,st_ch,use_bias)\n","        self.pool_b0 = nn.Conv2d(st_ch, st_ch*2, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_b1_0 = CCNR(st_ch*2,st_ch*2,use_bias)\n","        self.enc_b1_1 = CCNR(st_ch*2,st_ch*2,use_bias)\n","        self.pool_b1 = nn.Conv2d(st_ch*2, st_ch*4, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_b2_0 = CCNR(st_ch*4,st_ch*4,use_bias)\n","        self.enc_b2_1 = CCNR(st_ch*4,st_ch*4,use_bias)\n","        self.pool_b2 = nn.Conv2d(st_ch*4, st_ch*8, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_b3_0 = CCNR(st_ch*8,st_ch*8,use_bias)\n","        self.enc_b3_1 = CCNR(st_ch*8,st_ch*8,use_bias)\n","        self.pool_b3 = nn.Conv2d(st_ch*8, st_ch*16, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        #Encoder C layers\n","        self.enc_c0_0 = CCNR(in_ch,st_ch,use_bias)\n","        self.enc_c0_1 = CCNR(st_ch,st_ch,use_bias)\n","        self.pool_c0 = nn.Conv2d(st_ch, st_ch*2, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_c1_0 = CCNR(st_ch*2,st_ch*2,use_bias)\n","        self.enc_c1_1 = CCNR(st_ch*2,st_ch*2,use_bias)\n","        self.pool_c1 = nn.Conv2d(st_ch*2, st_ch*4, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_c2_0 = CCNR(st_ch*4,st_ch*4,use_bias)\n","        self.enc_c2_1 = CCNR(st_ch*4,st_ch*4,use_bias)\n","        self.pool_c2 = nn.Conv2d(st_ch*4, st_ch*8, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_c3_0 = CCNR(st_ch*8,st_ch*8,use_bias)\n","        self.enc_c3_1 = CCNR(st_ch*8,st_ch*8,use_bias)\n","        self.pool_c3 = nn.Conv2d(st_ch*8, st_ch*16, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        #Encoder D layers\n","        self.enc_d0_0 = CCNR(in_ch,st_ch,use_bias)\n","        self.enc_d0_1 = CCNR(st_ch,st_ch,use_bias)\n","        self.pool_d0 = nn.Conv2d(st_ch, st_ch*2, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_d1_0 = CCNR(st_ch*2,st_ch*2,use_bias)\n","        self.enc_d1_1 = CCNR(st_ch*2,st_ch*2,use_bias)\n","        self.pool_d1 = nn.Conv2d(st_ch*2, st_ch*4, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_d2_0 = CCNR(st_ch*4,st_ch*4,use_bias)\n","        self.enc_d2_1 = CCNR(st_ch*4,st_ch*4,use_bias)\n","        self.pool_d2 = nn.Conv2d(st_ch*4, st_ch*8, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        \n","        self.enc_d3_0 = CCNR(st_ch*8,st_ch*8,use_bias)\n","        self.enc_d3_1 = CCNR(st_ch*8,st_ch*8,use_bias)\n","        self.pool_d3 = nn.Conv2d(st_ch*8, st_ch*16, kernel_size=2, stride=2, bias=use_bias)\n","        \n","        #Decode Layers\n","        \n","        self.dec_3_0 = CCNR(st_ch*64,st_ch*64,use_bias)\n","        self.dec_3_1 = CCNR(st_ch*64,st_ch*64,use_bias)\n","        self.dec_3_2 = CCAM(st_ch*64)\n","        self.convT_3 = nn.ConvTranspose2d(st_ch*64,st_ch*32,kernel_size=2,stride=2,bias=use_bias)\n","        \n","        \n","        self.dec_2_0 = CCNR(st_ch*64,st_ch*32,use_bias)\n","        self.dec_2_1 = CCNR(st_ch*32,st_ch*32,use_bias)\n","        self.dec_2_2 = CCAM(st_ch*32)\n","        self.convT_2 = nn.ConvTranspose2d(st_ch*32,st_ch*16,kernel_size=2,stride=2,bias=use_bias)\n","        \n","        \n","        self.dec_1_0 = CCNR(st_ch*32,st_ch*16,use_bias)\n","        self.dec_1_1 = CCNR(st_ch*16,st_ch*16,use_bias)\n","        self.dec_1_2 = CCAM(st_ch*16)\n","        self.convT_1 = nn.ConvTranspose2d(st_ch*16,st_ch*8,kernel_size=2,stride=2,bias=use_bias)\n","        \n","        \n","        self.dec_0_0 = CCNR(st_ch*16,st_ch*8,use_bias)\n","        self.dec_0_1 = CCNR(st_ch*8,st_ch*8,use_bias)\n","        self.dec_0_2 = CCAM(st_ch*8)\n","        self.convT_0 = nn.ConvTranspose2d(st_ch*8,st_ch*4,kernel_size=2,stride=2,bias=use_bias)\n","        \n","        self.final_dec_0 = CCNR(st_ch*4,st_ch*4,use_bias)\n","        self.final_dec_1 = CCNR(st_ch*4,st_ch*4,use_bias)\n","        \n","        self.final_conv = nn.Conv2d(st_ch*4,1,kernel_size=1,stride=1,bias=use_bias)\n","        \n","        \n","    def forward(self,inputs):\n","      \n","        mask = inputs[:,4:,:,:]\n","        \n","        print(mask.shape,inputs[:,0:1,:,:].shape)\n","        \n","        a = torch.cat([inputs[:,0:1,:,:],mask],dim=1)\n","        b = torch.cat([inputs[:,1:2,:,:],mask],dim=1)\n","        c = torch.cat([inputs[:,2:3,:,:],mask],dim=1)\n","        d = torch.cat([inputs[:,3:4,:,:],mask],dim=1)\n","        \n","        mask = mask[:,:,0,0]\n","        \n","        down_a0 = self.enc_a0_1(self.enc_a0_0(a))\n","        pooled_a0 = self.pool_a0(down_a0)\n","        down_a1 = self.enc_a1_1(self.enc_a1_0(pooled_a0))\n","        pooled_a1 = self.pool_a1(down_a1)\n","        down_a2 = self.enc_a2_1(self.enc_a2_0(pooled_a1))\n","        pooled_a2 = self.pool_a2(down_a2)\n","        down_a3 = self.enc_a3_1(self.enc_a3_0(pooled_a2))\n","        pooled_a3 = self.pool_a3(down_a3)\n","        \n","        down_b0 = self.enc_b0_1(self.enc_b0_0(b))\n","        pooled_b0 = self.pool_b0(down_b0)\n","        down_b1 = self.enc_b1_1(self.enc_b1_0(pooled_b0))\n","        pooled_b1 = self.pool_b1(down_b1)\n","        down_b2 = self.enc_b2_1(self.enc_b2_0(pooled_b1))\n","        pooled_b2 = self.pool_b2(down_b2)\n","        down_b3 = self.enc_b3_1(self.enc_b3_0(pooled_b2))\n","        pooled_b3 = self.pool_b3(down_b3)\n","        \n","        down_c0 = self.enc_c0_1(self.enc_c0_0(c))\n","        pooled_c0 = self.pool_c0(down_c0)\n","        down_c1 = self.enc_c1_1(self.enc_c1_0(pooled_c0))\n","        pooled_c1 = self.pool_c1(down_c1)\n","        down_c2 = self.enc_c2_1(self.enc_c2_0(pooled_c1))\n","        pooled_c2 = self.pool_c2(down_c2)\n","        down_c3 = self.enc_c3_1(self.enc_c3_0(pooled_c2))\n","        pooled_c3 = self.pool_c3(down_c3)\n","        \n","        down_d0 = self.enc_d0_1(self.enc_d0_0(d))\n","        pooled_d0 = self.pool_d0(down_d0)\n","        down_d1 = self.enc_d1_1(self.enc_d1_0(pooled_d0))\n","        pooled_d1 = self.pool_d1(down_d1)\n","        down_d2 = self.enc_d2_1(self.enc_d2_0(pooled_d1))\n","        pooled_d2 = self.pool_d2(down_d2)\n","        down_d3 = self.enc_d3_1(self.enc_d3_0(pooled_d2))\n","        pooled_d3 = self.pool_d3(down_d3)\n","        \n","        \n","        up_3 = self.dec_3_0(torch.cat([pooled_a3,pooled_b3,pooled_c3,pooled_d3],dim=1))\n","        up_3 = self.dec_3_2(self.dec_3_1(up_3),mask)\n","        up_3 = self.convT_3(up_3)        \n","        \n","        \n","        up_2 = self.dec_2_0(torch.cat([up_3,pooled_a2,pooled_b2,pooled_c2,pooled_d2],dim=1))\n","        up_2 = self.dec_2_2(self.dec_2_1(up_2),mask)\n","        up_2 = self.convT_2(up_2)\n","        \n","        up_1 = self.dec_1_0(torch.cat([up_2,pooled_a1,pooled_b1,pooled_c1,pooled_d1],dim=1))\n","        up_1 = self.dec_1_2(self.dec_1_1(up_1),mask)\n","        up_1 = self.convT_1(up_1)\n","        \n","        \n","        up_0 = self.dec_0_0(torch.cat([up_1,pooled_a0,pooled_b0,pooled_c0,pooled_d0],dim=1))\n","        up_0 = self.dec_0_2(self.dec_0_1(up_0),mask)\n","        up_0 = self.convT_0(up_0)\n","        \n","        fin_img = self.final_dec_1(self.final_dec_0(up_0))\n","        \n","        return nn.ReLU(self.final_conv(fin_img))     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2o4czOVfrCwm","colab_type":"code","colab":{}},"source":["class Discriminator(nn.Module):\n","  \n","  def __init__(self,use_bias):\n","    \n","      super(Discriminator,self).__init__()\n","      self.use_bias = use_bias\n","      self.path1 = nn.Sequential(*[\n","          nn.Conv2d(1,4,kernel_size=3,stride=1,bias=use_bias),\n","          nn.LeakyReLU(),\n","          nn.Conv2d(4,4,kernel_size=3,stride=1,bias=use_bias),\n","          nn.LeakyReLU(),\n","          nn.Conv2d(4,4,kernel_size=3,stride=1,bias=use_bias),\n","          nn.LeakyReLU(),\n","          nn.Conv2d(4,16,kernel_size=4,stride=4,bias=False)   \n","      ])\n","      \n","      self.path2 = nn.Sequential(*[\n","          nn.Conv2d(1,4,kernel_size=3,stride=1,bias=use_bias,padding=2),\n","          nn.MaxPool2d(2,2),          \n","          nn.Conv2d(4,8,kernel_size=3,stride=1,bias=use_bias,padding=1),\n","          nn.MaxPool2d(2,2),\n","          nn.Conv2d(8,16,kernel_size=3,stride=1,bias=use_bias),\n","          nn.LeakyReLU()      \n","      ])\n","      \n","      self.path3 = nn.Sequential(*[\n","          nn.Conv2d(1,16,kernel_size=4,stride=4,bias=False,padding=1),\n","          nn.Conv2d(16,16,kernel_size=3,stride=1,bias=use_bias,padding=2),\n","          nn.LeakyReLU(),\n","          nn.Conv2d(16,16,kernel_size=3,stride=1,bias=use_bias),\n","          nn.LeakyReLU(),\n","          nn.Conv2d(16,16,kernel_size=3,stride=1,bias=use_bias)\n","      ])\n","      \n","      \n","      self.merge = nn.Sequential(*[\n","          nn.Conv2d(16*3,32,kernel_size=4,stride=2,bias=False),\n","          nn.LeakyReLU(),\n","          nn.Conv2d(32,64,kernel_size=4,stride=2,bias=False),\n","          nn.LeakyReLU()\n","      ])\n","      \n","      self.rf = nn.Sequential(*[\n","          nn.Conv2d(64,128,kernel_size=4,stride=2,bias=False),\n","          nn.LeakyReLU(),\n","          nn.Dropout(0.5),\n","          nn.Conv2d(128,1,kernel_size=5,stride=1,bias=False)\n","      ])\n","      \n","      self.classify = nn.Sequential(*[\n","          nn.Conv2d(64,128,kernel_size=4,stride=2,bias=False),\n","          nn.LeakyReLU(),\n","          nn.Dropout(0.5),\n","          nn.Conv2d(128,4,kernel_size=5,stride=1,bias=False)\n","      ])\n","      \n","  def forward(self,img):\n","    \n","    o1 = self.path1(img)\n","    o2 = self.path2(img)\n","    o3 = self.path3(img)\n","    merge_out = self.merge(torch.cat([o1,o2,o3],dim=1))\n","    rf_out = self.rf(merge_out)\n","    class_out = self.classify(merge_out)\n","    \n","    return rf_out,class_out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lVd_Xhfuq8lR","colab_type":"code","colab":{}},"source":["dis = Discriminator(False).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EmOmvVWQ2zod","colab_type":"code","outputId":"40bbdaa7-e11c-4e8c-d8cb-30878f8a2665","executionInfo":{"status":"ok","timestamp":1568787682852,"user_tz":-330,"elapsed":2175,"user":{"displayName":"JAJAL KUSH","photoUrl":"","userId":"11020206420045709190"}},"colab":{"base_uri":"https://localhost:8080/","height":756}},"source":["torchsummary.summary(dis,input_size=(1,240,240))"],"execution_count":47,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 4, 238, 238]              36\n","         LeakyReLU-2          [-1, 4, 238, 238]               0\n","            Conv2d-3          [-1, 4, 236, 236]             144\n","         LeakyReLU-4          [-1, 4, 236, 236]               0\n","            Conv2d-5          [-1, 4, 234, 234]             144\n","         LeakyReLU-6          [-1, 4, 234, 234]               0\n","            Conv2d-7           [-1, 16, 58, 58]           1,024\n","            Conv2d-8          [-1, 4, 242, 242]              36\n","         MaxPool2d-9          [-1, 4, 121, 121]               0\n","           Conv2d-10          [-1, 8, 121, 121]             288\n","        MaxPool2d-11            [-1, 8, 60, 60]               0\n","           Conv2d-12           [-1, 16, 58, 58]           1,152\n","        LeakyReLU-13           [-1, 16, 58, 58]               0\n","           Conv2d-14           [-1, 16, 60, 60]             256\n","           Conv2d-15           [-1, 16, 62, 62]           2,304\n","        LeakyReLU-16           [-1, 16, 62, 62]               0\n","           Conv2d-17           [-1, 16, 60, 60]           2,304\n","        LeakyReLU-18           [-1, 16, 60, 60]               0\n","           Conv2d-19           [-1, 16, 58, 58]           2,304\n","           Conv2d-20           [-1, 32, 28, 28]          24,576\n","        LeakyReLU-21           [-1, 32, 28, 28]               0\n","           Conv2d-22           [-1, 64, 13, 13]          32,768\n","        LeakyReLU-23           [-1, 64, 13, 13]               0\n","           Conv2d-24            [-1, 128, 5, 5]         131,072\n","        LeakyReLU-25            [-1, 128, 5, 5]               0\n","          Dropout-26            [-1, 128, 5, 5]               0\n","           Conv2d-27              [-1, 1, 1, 1]           3,200\n","           Conv2d-28            [-1, 128, 5, 5]         131,072\n","        LeakyReLU-29            [-1, 128, 5, 5]               0\n","          Dropout-30            [-1, 128, 5, 5]               0\n","           Conv2d-31              [-1, 4, 1, 1]          12,800\n","================================================================\n","Total params: 345,480\n","Trainable params: 345,480\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.22\n","Forward/backward pass size (MB): 18.14\n","Params size (MB): 1.32\n","Estimated Total Size (MB): 19.68\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IGZjuyyC2zog","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}